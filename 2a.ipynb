{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W7MYyHXjQbx"
      },
      "source": [
        "Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP8_TyoKEMla"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LE5D4ibkoFl",
        "outputId": "689cc08f-5b53-4f8f-b1b8-6e394d8cad28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bQLhRcADjQb2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "# TODO: implement here your custom dataset class for Cityscapes\n",
        "\n",
        "\n",
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, root_dir, split='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.image_dir = os.path.join(self.root_dir, 'images', self.split)\n",
        "        self.label_dir = os.path.join(self.root_dir, 'gtFine', self.split)\n",
        "        self.image_folders = os.listdir(self.image_dir)\n",
        "        self.images = []\n",
        "\n",
        "        for folder in self.image_folders:\n",
        "            images_in_folder = os.listdir(os.path.join(self.image_dir, folder))\n",
        "            self.images.extend(images_in_folder)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder_name = self.images[idx].split('_')[0]\n",
        "        img_name = os.path.join(self.image_dir, folder_name, self.images[idx])\n",
        "        label_name = os.path.join(self.label_dir, folder_name, self.images[idx].replace('leftImg8bit', 'gtFine_labelTrainIds'))\n",
        "\n",
        "        image = np.array(Image.open(img_name).convert('RGB'))[::2,::2]\n",
        "        # image = torch.tensor(image)\n",
        "        label = np.array(Image.open(label_name))[::2,::2]\n",
        "        label = torch.tensor(label).long()\n",
        "        # This code need to updated.\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jEKpGBg5jQb5"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hJdnjm9ejQb6"
      },
      "outputs": [],
      "source": [
        "train_dataset = CityscapesDataset('/content/drive/MyDrive/MLDL_project/MLDL2024_project1/datasets/Cityspaces', transform=transform, split='train')\n",
        "val_dataset = CityscapesDataset('/content/drive/MyDrive/MLDL_project/MLDL2024_project1/datasets/Cityspaces', transform=transform, split='val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qRib7A3cjQb6"
      },
      "outputs": [],
      "source": [
        "# Create a DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader_train = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "dataloader_val = DataLoader(val_dataset, batch_size=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOAvJ_1AjQb7",
        "outputId": "e81d8caa-a93e-43f2-d4a7-abc65c947be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 1572\n",
            "Number of validation samples: 500\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_train_samples = len(train_dataset)\n",
        "num_val_samples = len(val_dataset)\n",
        "\n",
        "print(f'Number of training samples: {num_train_samples}')\n",
        "print(f'Number of validation samples: {num_val_samples}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yheASVdL4nuN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfIPq_ajQb8"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7fquv-ETjQb8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "affine_par = True\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        # change\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        padding = dilation\n",
        "        # change\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                               padding=padding, bias=False, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n",
        "        for i in self.bn2.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n",
        "        for i in self.bn3.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.conv2d_list = nn.ModuleList()\n",
        "        for dilation, padding in zip(dilation_series, padding_series):\n",
        "            self.conv2d_list.append(\n",
        "                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n",
        "                          dilation=dilation, bias=True))\n",
        "\n",
        "        for m in self.conv2d_list:\n",
        "            m.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv2d_list[0](x)\n",
        "        for i in range(len(self.conv2d_list) - 1):\n",
        "            out += self.conv2d_list[i + 1](x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetMulti(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes):\n",
        "        self.inplanes = 64\n",
        "        super(ResNetMulti, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n",
        "        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
        "        downsample = None\n",
        "        if (stride != 1\n",
        "                or self.inplanes != planes * block.expansion\n",
        "                or dilation == 2\n",
        "                or dilation == 4):\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n",
        "        for i in downsample._modules['1'].parameters():\n",
        "            i.requires_grad = False\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, dilation=dilation))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, H, W = x.size()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer6(x)\n",
        "\n",
        "        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n",
        "\n",
        "        # if self.training == True:\n",
        "        #     return x, None, None\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_1x_lr_params_no_scale(self):\n",
        "        \"\"\"\n",
        "        This generator returns all the parameters of the net except for\n",
        "        the last classification layer. Note that for each batchnorm layer,\n",
        "        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n",
        "        any batchnorm parameter\n",
        "        \"\"\"\n",
        "        b = []\n",
        "\n",
        "        b.append(self.conv1)\n",
        "        b.append(self.bn1)\n",
        "        b.append(self.layer1)\n",
        "        b.append(self.layer2)\n",
        "        b.append(self.layer3)\n",
        "        b.append(self.layer4)\n",
        "\n",
        "        for i in range(len(b)):\n",
        "            for j in b[i].modules():\n",
        "                jj = 0\n",
        "                for k in j.parameters():\n",
        "                    jj += 1\n",
        "                    if k.requires_grad:\n",
        "                        yield k\n",
        "\n",
        "    def get_10x_lr_params(self):\n",
        "        \"\"\"\n",
        "        This generator returns all the parameters for the last layer of the net,\n",
        "        which does the classification of pixel into classes\n",
        "        \"\"\"\n",
        "        b = []\n",
        "        if self.multi_level:\n",
        "            b.append(self.layer5.parameters())\n",
        "        b.append(self.layer6.parameters())\n",
        "\n",
        "        for j in range(len(b)):\n",
        "            for i in b[j]:\n",
        "                yield i\n",
        "\n",
        "    def optim_parameters(self, lr):\n",
        "        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n",
        "                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n",
        "\n",
        "\n",
        "def get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='/content/drive/MyDrive/MLDL_project/MLDL2024_project1/DeepLab_resnet_pretrained_imagenet.pth'):\n",
        "    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n",
        "\n",
        "    # Pretraining loading\n",
        "    if pretrain:\n",
        "        print('Deeplab pretraining loading...')\n",
        "        saved_state_dict = torch.load(pretrain_model_path)\n",
        "\n",
        "        new_params = model.state_dict().copy()\n",
        "        for i in saved_state_dict:\n",
        "            i_parts = i.split('.')\n",
        "            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n",
        "        model.load_state_dict(new_params, strict=False)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBuDbh3vjQb-"
      },
      "source": [
        "Train and validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny-Hn0OpjQb-",
        "outputId": "4d54a7f8-fd1a-4633-cd57-08ad87bb1cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,   1,   2,   4,   5,   6,   7,   8,  10,  11,  12,  13,  15,  17,\n",
              "         18, 255])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0][1].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UygFgCN6jQb_",
        "outputId": "7e3161d8-20c6-4765-ebd3-d996fb7cb96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deeplab pretraining loading...\n"
          ]
        }
      ],
      "source": [
        "model = get_deeplab_v2()\n",
        "model.eval()\n",
        "\n",
        "input_tensor = train_dataset[0][0]\n",
        "input_batch = input_tensor.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB1xhQao3UTB"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = model(input_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3egUQow3p4J",
        "outputId": "e2ad2317-651e-47d5-bbdb-bda510de9283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 512, 1024])\n",
            "torch.Size([1, 19, 512, 1024])\n"
          ]
        }
      ],
      "source": [
        "print(input_tensor.shape)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPBZy92v8LMH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6hJEELV5dy6"
      },
      "source": [
        "Trainning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnWIBshs3vX7",
        "outputId": "5e55606b-23f4-4ab6-cff1-30ac6772fd6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deeplab pretraining loading...\n",
            "[1,   200] loss: 0.964\n",
            "[1,   400] loss: 0.512\n",
            "[1,   600] loss: 0.480\n",
            "[2,   200] loss: 0.406\n",
            "[2,   400] loss: 0.368\n",
            "[2,   600] loss: 0.374\n",
            "[3,   200] loss: 0.311\n",
            "[3,   400] loss: 0.321\n",
            "[3,   600] loss: 0.320\n",
            "[4,   200] loss: 0.319\n",
            "[4,   400] loss: 0.314\n",
            "[4,   600] loss: 0.269\n",
            "[5,   200] loss: 0.272\n",
            "[5,   400] loss: 0.239\n",
            "[5,   400] loss: 0.239\n",
            "[5,   600] loss: 0.261\n",
            "[5,   600] loss: 0.261\n",
            "Finished Training\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = get_deeplab_v2().cuda()\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training model\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(dataloader_train, 0):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 200))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86YSJG077D7D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYjcbuGb7DCu"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "PATH = '/content/drive/MyDrive/MLDL_project/MLDL2024_project1/models/deeplabv2/cityspace_segmentation_model.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn_JXppIvvTU"
      },
      "source": [
        "Validation process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns6I-IZHzse0",
        "outputId": "ad4fc1c6-eeae-4d75-b9bf-01e1e8372571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deeplab pretraining loading...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "PATH = '/content/drive/MyDrive/MLDL_project/MLDL2024_project1/models/deeplabv2/cityspace_segmentation_model.pth'\n",
        "model = get_deeplab_v2().cuda()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3K0f_MiOHAka"
      },
      "outputs": [],
      "source": [
        "def fast_hist(a, b, n):\n",
        "    '''\n",
        "    a and b are ground truth and predict respectively\n",
        "    n is the number of classes\n",
        "    '''\n",
        "    k = (a >= 0) & (a < n)\n",
        "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
        "\n",
        "\n",
        "def per_class_iou(hist):\n",
        "    epsilon = 1e-5\n",
        "    return (np.diag(hist)) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rByWVFdgvuNY"
      },
      "outputs": [],
      "source": [
        "def mean_iou(outputs, labels, num_classes):\n",
        "    hist = 0\n",
        "    for i in range(len(outputs)):\n",
        "        output, label = outputs[i].cpu().numpy().reshape(-1,), labels[i].cpu().numpy().reshape(-1,)\n",
        "        hist += fast_hist(label, output, num_classes)\n",
        "    return np.mean(per_class_iou(hist))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCl0AOnjICcR",
        "outputId": "31e19358-077a-4f01-e5a2-98a5c27bc378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg. Validation Loss: 0.40124328154325484, Avg. mIoU: 0.3175532447539691\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "val_loss = 0.0\n",
        "total_miou = 0.0\n",
        "num_batches = 0\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(dataloader_val, 0):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()\n",
        "        outputs = torch.argmax(outputs, dim=1)\n",
        "        miou = mean_iou(outputs, labels, 19)\n",
        "        total_miou += miou\n",
        "        num_batches += 1\n",
        "\n",
        "avg_val_loss = val_loss / len(dataloader_val)\n",
        "avg_miou = total_miou / num_batches\n",
        "print(f\"Avg. Validation Loss: {avg_val_loss}, Avg. mIoU: {avg_miou}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qHDiFfE2tx2"
      },
      "source": [
        "Flops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVmFKcxm2-K7",
        "outputId": "122a129f-f611-4d0f-d976-0d356ef4d5c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.25.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.11.0)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=15079318fb955240f4fcd26aab78ba8a84d0cc1527c8b8651996089039506b0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=4ab2bee1ef5375cedde61f0b4bee17b048e08c9cba0831a104b018bea4c8f776\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install -U fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za6HIEhd2uwc",
        "outputId": "ca5e4a1b-314b-4e8f-f825-3c164b88c8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| module                         | #parameters or shape   | #flops     |\n",
            "|:-------------------------------|:-----------------------|:-----------|\n",
            "| model                          | 43.901M                | 2.9G       |\n",
            "|  conv1                         |  9.408K                |  4.817M    |\n",
            "|   conv1.weight                 |   (64, 3, 7, 7)        |            |\n",
            "|  bn1                           |  0.128K                |  65.536K   |\n",
            "|   bn1.weight                   |   (64,)                |            |\n",
            "|   bn1.bias                     |   (64,)                |            |\n",
            "|  layer1                        |  0.216M                |  55.678M   |\n",
            "|   layer1.0                     |   75.008K              |   19.352M  |\n",
            "|    layer1.0.conv1              |    4.096K              |    1.057M  |\n",
            "|    layer1.0.bn1                |    0.128K              |    33.024K |\n",
            "|    layer1.0.conv2              |    36.864K             |    9.511M  |\n",
            "|    layer1.0.bn2                |    0.128K              |    33.024K |\n",
            "|    layer1.0.conv3              |    16.384K             |    4.227M  |\n",
            "|    layer1.0.bn3                |    0.512K              |    0.132M  |\n",
            "|    layer1.0.downsample         |    16.896K             |    4.359M  |\n",
            "|   layer1.1                     |   70.4K                |   18.163M  |\n",
            "|    layer1.1.conv1              |    16.384K             |    4.227M  |\n",
            "|    layer1.1.bn1                |    0.128K              |    33.024K |\n",
            "|    layer1.1.conv2              |    36.864K             |    9.511M  |\n",
            "|    layer1.1.bn2                |    0.128K              |    33.024K |\n",
            "|    layer1.1.conv3              |    16.384K             |    4.227M  |\n",
            "|    layer1.1.bn3                |    0.512K              |    0.132M  |\n",
            "|   layer1.2                     |   70.4K                |   18.163M  |\n",
            "|    layer1.2.conv1              |    16.384K             |    4.227M  |\n",
            "|    layer1.2.bn1                |    0.128K              |    33.024K |\n",
            "|    layer1.2.conv2              |    36.864K             |    9.511M  |\n",
            "|    layer1.2.bn2                |    0.128K              |    33.024K |\n",
            "|    layer1.2.conv3              |    16.384K             |    4.227M  |\n",
            "|    layer1.2.bn3                |    0.512K              |    0.132M  |\n",
            "|  layer2                        |  1.22M                 |  79.273M   |\n",
            "|   layer2.0                     |   0.379M               |   24.66M   |\n",
            "|    layer2.0.conv1              |    32.768K             |    2.13M   |\n",
            "|    layer2.0.bn1                |    0.256K              |    16.64K  |\n",
            "|    layer2.0.conv2              |    0.147M              |    9.585M  |\n",
            "|    layer2.0.bn2                |    0.256K              |    16.64K  |\n",
            "|    layer2.0.conv3              |    65.536K             |    4.26M   |\n",
            "|    layer2.0.bn3                |    1.024K              |    66.56K  |\n",
            "|    layer2.0.downsample         |    0.132M              |    8.586M  |\n",
            "|   layer2.1                     |   0.28M                |   18.204M  |\n",
            "|    layer2.1.conv1              |    65.536K             |    4.26M   |\n",
            "|    layer2.1.bn1                |    0.256K              |    16.64K  |\n",
            "|    layer2.1.conv2              |    0.147M              |    9.585M  |\n",
            "|    layer2.1.bn2                |    0.256K              |    16.64K  |\n",
            "|    layer2.1.conv3              |    65.536K             |    4.26M   |\n",
            "|    layer2.1.bn3                |    1.024K              |    66.56K  |\n",
            "|   layer2.2                     |   0.28M                |   18.204M  |\n",
            "|    layer2.2.conv1              |    65.536K             |    4.26M   |\n",
            "|    layer2.2.bn1                |    0.256K              |    16.64K  |\n",
            "|    layer2.2.conv2              |    0.147M              |    9.585M  |\n",
            "|    layer2.2.bn2                |    0.256K              |    16.64K  |\n",
            "|    layer2.2.conv3              |    65.536K             |    4.26M   |\n",
            "|    layer2.2.bn3                |    1.024K              |    66.56K  |\n",
            "|   layer2.3                     |   0.28M                |   18.204M  |\n",
            "|    layer2.3.conv1              |    65.536K             |    4.26M   |\n",
            "|    layer2.3.bn1                |    0.256K              |    16.64K  |\n",
            "|    layer2.3.conv2              |    0.147M              |    9.585M  |\n",
            "|    layer2.3.bn2                |    0.256K              |    16.64K  |\n",
            "|    layer2.3.conv3              |    65.536K             |    4.26M   |\n",
            "|    layer2.3.bn3                |    1.024K              |    66.56K  |\n",
            "|  layer3                        |  26.09M                |  1.696G    |\n",
            "|   layer3.0                     |   1.512M               |   98.309M  |\n",
            "|    layer3.0.conv1              |    0.131M              |    8.52M   |\n",
            "|    layer3.0.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.0.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.0.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.0.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.0.bn3                |    2.048K              |    0.133M  |\n",
            "|    layer3.0.downsample         |    0.526M              |    34.212M |\n",
            "|   layer3.1                     |   1.117M               |   72.617M  |\n",
            "|    layer3.1.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.1.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.1.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.1.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.1.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.1.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.2                     |   1.117M               |   72.617M  |\n",
            "|    layer3.2.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.2.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.2.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.2.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.2.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.2.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.3                     |   1.117M               |   72.617M  |\n",
            "|    layer3.3.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.3.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.3.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.3.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.3.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.3.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.4                     |   1.117M               |   72.617M  |\n",
            "|    layer3.4.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.4.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.4.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.4.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.4.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.4.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.5                     |   1.117M               |   72.617M  |\n",
            "|    layer3.5.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.5.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.5.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.5.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.5.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.5.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.6                     |   1.117M               |   72.617M  |\n",
            "|    layer3.6.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.6.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.6.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.6.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.6.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.6.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.7                     |   1.117M               |   72.617M  |\n",
            "|    layer3.7.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.7.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.7.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.7.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.7.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.7.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.8                     |   1.117M               |   72.617M  |\n",
            "|    layer3.8.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.8.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.8.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.8.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.8.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.8.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.9                     |   1.117M               |   72.617M  |\n",
            "|    layer3.9.conv1              |    0.262M              |    17.039M |\n",
            "|    layer3.9.bn1                |    0.512K              |    33.28K  |\n",
            "|    layer3.9.conv2              |    0.59M               |    38.339M |\n",
            "|    layer3.9.bn2                |    0.512K              |    33.28K  |\n",
            "|    layer3.9.conv3              |    0.262M              |    17.039M |\n",
            "|    layer3.9.bn3                |    2.048K              |    0.133M  |\n",
            "|   layer3.10                    |   1.117M               |   72.617M  |\n",
            "|    layer3.10.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.10.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.10.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.10.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.10.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.10.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.11                    |   1.117M               |   72.617M  |\n",
            "|    layer3.11.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.11.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.11.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.11.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.11.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.11.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.12                    |   1.117M               |   72.617M  |\n",
            "|    layer3.12.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.12.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.12.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.12.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.12.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.12.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.13                    |   1.117M               |   72.617M  |\n",
            "|    layer3.13.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.13.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.13.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.13.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.13.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.13.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.14                    |   1.117M               |   72.617M  |\n",
            "|    layer3.14.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.14.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.14.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.14.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.14.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.14.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.15                    |   1.117M               |   72.617M  |\n",
            "|    layer3.15.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.15.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.15.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.15.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.15.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.15.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.16                    |   1.117M               |   72.617M  |\n",
            "|    layer3.16.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.16.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.16.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.16.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.16.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.16.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.17                    |   1.117M               |   72.617M  |\n",
            "|    layer3.17.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.17.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.17.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.17.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.17.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.17.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.18                    |   1.117M               |   72.617M  |\n",
            "|    layer3.18.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.18.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.18.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.18.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.18.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.18.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.19                    |   1.117M               |   72.617M  |\n",
            "|    layer3.19.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.19.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.19.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.19.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.19.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.19.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.20                    |   1.117M               |   72.617M  |\n",
            "|    layer3.20.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.20.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.20.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.20.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.20.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.20.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.21                    |   1.117M               |   72.617M  |\n",
            "|    layer3.21.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.21.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.21.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.21.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.21.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.21.bn3               |    2.048K              |    0.133M  |\n",
            "|   layer3.22                    |   1.117M               |   72.617M  |\n",
            "|    layer3.22.conv1             |    0.262M              |    17.039M |\n",
            "|    layer3.22.bn1               |    0.512K              |    33.28K  |\n",
            "|    layer3.22.conv2             |    0.59M               |    38.339M |\n",
            "|    layer3.22.bn2               |    0.512K              |    33.28K  |\n",
            "|    layer3.22.conv3             |    0.262M              |    17.039M |\n",
            "|    layer3.22.bn3               |    2.048K              |    0.133M  |\n",
            "|  layer4                        |  14.965M               |  0.973G    |\n",
            "|   layer4.0                     |   6.04M                |   0.393G   |\n",
            "|    layer4.0.conv1              |    0.524M              |    34.079M |\n",
            "|    layer4.0.bn1                |    1.024K              |    66.56K  |\n",
            "|    layer4.0.conv2              |    2.359M              |    0.153G  |\n",
            "|    layer4.0.bn2                |    1.024K              |    66.56K  |\n",
            "|    layer4.0.conv3              |    1.049M              |    68.157M |\n",
            "|    layer4.0.bn3                |    4.096K              |    0.266M  |\n",
            "|    layer4.0.downsample         |    2.101M              |    0.137G  |\n",
            "|   layer4.1                     |   4.463M               |   0.29G    |\n",
            "|    layer4.1.conv1              |    1.049M              |    68.157M |\n",
            "|    layer4.1.bn1                |    1.024K              |    66.56K  |\n",
            "|    layer4.1.conv2              |    2.359M              |    0.153G  |\n",
            "|    layer4.1.bn2                |    1.024K              |    66.56K  |\n",
            "|    layer4.1.conv3              |    1.049M              |    68.157M |\n",
            "|    layer4.1.bn3                |    4.096K              |    0.266M  |\n",
            "|   layer4.2                     |   4.463M               |   0.29G    |\n",
            "|    layer4.2.conv1              |    1.049M              |    68.157M |\n",
            "|    layer4.2.bn1                |    1.024K              |    66.56K  |\n",
            "|    layer4.2.conv2              |    2.359M              |    0.153G  |\n",
            "|    layer4.2.bn2                |    1.024K              |    66.56K  |\n",
            "|    layer4.2.conv3              |    1.049M              |    68.157M |\n",
            "|    layer4.2.bn3                |    4.096K              |    0.266M  |\n",
            "|  layer6.conv2d_list            |  1.401M                |  91.054M   |\n",
            "|   layer6.conv2d_list.0         |   0.35M                |   22.764M  |\n",
            "|    layer6.conv2d_list.0.weight |    (19, 2048, 3, 3)    |            |\n",
            "|    layer6.conv2d_list.0.bias   |    (19,)               |            |\n",
            "|   layer6.conv2d_list.1         |   0.35M                |   22.764M  |\n",
            "|    layer6.conv2d_list.1.weight |    (19, 2048, 3, 3)    |            |\n",
            "|    layer6.conv2d_list.1.bias   |    (19,)               |            |\n",
            "|   layer6.conv2d_list.2         |   0.35M                |   22.764M  |\n",
            "|    layer6.conv2d_list.2.weight |    (19, 2048, 3, 3)    |            |\n",
            "|    layer6.conv2d_list.2.bias   |    (19,)               |            |\n",
            "|   layer6.conv2d_list.3         |   0.35M                |   22.764M  |\n",
            "|    layer6.conv2d_list.3.weight |    (19, 2048, 3, 3)    |            |\n",
            "|    layer6.conv2d_list.3.bias   |    (19,)               |            |\n"
          ]
        }
      ],
      "source": [
        "from fvcore.nn import FlopCountAnalysis, flop_count_table\n",
        "\n",
        "# -----------------------------\n",
        "# Initizialize your model here\n",
        "# -----------------------------\n",
        "\n",
        "height = train_dataset[0][0].shape[0]\n",
        "width = train_dataset[0][0].shape[1]\n",
        "image = torch.zeros((1, 3, height, width)).cuda()\n",
        "\n",
        "flops = FlopCountAnalysis(model, image)\n",
        "print(flop_count_table(flops))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsFTGael3Brh"
      },
      "source": [
        "Latency and FPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk1qMMly3Awu",
        "outputId": "32e011bf-fd01-4439-f5ec-66c0950fd185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Latency: 17.546113000000002 ms\n",
            "Std Latency: 1.4466578594232298 ms\n",
            "Mean FPS: 57.244554603897036\n",
            "Std FPS: 3.276287355502824\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "height = train_dataset[0][0].shape[0]\n",
        "width = train_dataset[0][0].shape[1]\n",
        "image = torch.zeros((1, 3, height, width)).cuda()\n",
        "\n",
        "latency = np.zeros(1000)\n",
        "fps = np.zeros(1000)\n",
        "for i in range(1000):\n",
        "  start = datetime.now()\n",
        "  output = model(image)\n",
        "  end = datetime.now()\n",
        "  time_diff = end - start\n",
        "  time_diff_seconds = time_diff.total_seconds()\n",
        "  latency[i] = time_diff_seconds\n",
        "  fps[i] = 1/time_diff_seconds\n",
        "\n",
        "meanLatency = np.mean(latency)*1000\n",
        "stdLatency = np.std(latency)*1000\n",
        "meanFPS = np.mean(fps)\n",
        "stdFPS = np.std(fps)\n",
        "\n",
        "print(f\"Mean Latency: {meanLatency} ms\")\n",
        "print(f\"Std Latency: {stdLatency} ms\")\n",
        "print(f\"Mean FPS: {meanFPS}\")\n",
        "print(f\"Std FPS: {stdFPS}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd7VV9EB-TI7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
